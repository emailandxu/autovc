{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "narrative-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from model_bl import D_VECTOR\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "from librosa.filters import mel\n",
    "from numpy.random import RandomState\n",
    "from scipy.signal import get_window\n",
    "from math import ceil\n",
    "from model_vc import Generator\n",
    "from synthesis import build_model, wavegen\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "extra-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeakerEmbedder():\n",
    "    def __init__(self,model_path='3000000-BL.ckpt'):\n",
    "        self.C = D_VECTOR(dim_input=80, dim_cell=768, dim_emb=256).eval().cuda()\n",
    "        c_checkpoint = torch.load(model_path)\n",
    "        new_state_dict = OrderedDict()\n",
    "        for key, val in c_checkpoint['model_b'].items():\n",
    "            new_key = key[7:]\n",
    "            new_state_dict[new_key] = val\n",
    "        C.load_state_dict(new_state_dict)\n",
    "    \n",
    "    @staticmethod\n",
    "    def melspec(path):\n",
    "        def butter_highpass(cutoff, fs, order=5):\n",
    "            nyq = 0.5 * fs\n",
    "            normal_cutoff = cutoff / nyq\n",
    "            b, a = signal.butter(order, normal_cutoff, btype='high', analog=False)\n",
    "            return b, a\n",
    "\n",
    "\n",
    "        def pySTFT(x, fft_length=1024, hop_length=256):\n",
    "\n",
    "            x = np.pad(x, int(fft_length//2), mode='reflect')\n",
    "\n",
    "            noverlap = fft_length - hop_length\n",
    "            shape = x.shape[:-1]+((x.shape[-1]-noverlap)//hop_length, fft_length)\n",
    "            strides = x.strides[:-1]+(hop_length*x.strides[-1], x.strides[-1])\n",
    "            result = np.lib.stride_tricks.as_strided(x, shape=shape,\n",
    "                                                     strides=strides)\n",
    "\n",
    "            fft_window = get_window('hann', fft_length, fftbins=True)\n",
    "            result = np.fft.rfft(fft_window * result, n=fft_length).T\n",
    "\n",
    "            return np.abs(result)    \n",
    "\n",
    "\n",
    "        mel_basis = mel(16000, 1024, fmin=90, fmax=7600, n_mels=80).T\n",
    "        min_level = np.exp(-100 / 20 * np.log(10))\n",
    "        b, a = butter_highpass(30, 16000, order=5)\n",
    "\n",
    "        x, fs = sf.read(path)\n",
    "        # Remove drifting noise\n",
    "        y = signal.filtfilt(b, a, x)\n",
    "        # Ddd a little random noise for model roubstness\n",
    "        # prng = RandomState(225) \n",
    "        # wav = y * 0.96 + (prng.rand(y.shape[0])-0.5)*1e-06\n",
    "        wav = y\n",
    "        # Compute spect\n",
    "        D = pySTFT(wav).T\n",
    "        # Convert to mel and normalize\n",
    "        D_mel = np.dot(D, mel_basis)\n",
    "        D_db = 20 * np.log10(np.maximum(min_level, D_mel)) - 16\n",
    "        S = np.clip((D_db + 100) / 100, 0, 1)    \n",
    "        S = S.astype(np.float32)\n",
    "        return S\n",
    "    \n",
    "    def __call__(self, path):\n",
    "        tmp = SpeakerEmbedder.melspec(path)\n",
    "        len_crop = 128\n",
    "        left = np.random.randint(0, tmp.shape[0]-len_crop)\n",
    "        melsp = torch.from_numpy(tmp[np.newaxis, left:left+len_crop, :]).cuda()\n",
    "        with torch.no_grad():\n",
    "            emb = self.C(melsp)\n",
    "        return emb.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "biological-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechConverter():\n",
    "    def __init__(self):\n",
    "        self.device = 'cuda:0'\n",
    "        self.G = Generator(32,256,512,32).eval().to(self.device)\n",
    "\n",
    "        g_checkpoint = torch.load('autovc.ckpt', map_location=\"cuda:0\")\n",
    "        self.G.load_state_dict(g_checkpoint['model'])\n",
    "    \n",
    "    def __call__(self, x_org, emb_org, emb_trg):\n",
    "        x_org, len_pad = SpeechConverter.pad_seq(x_org)\n",
    "        uttr_org = torch.from_numpy(x_org[np.newaxis, :, :]).to(self.device)\n",
    "        emb_org = torch.from_numpy(emb_org[np.newaxis, :]).to(self.device)\n",
    "        emb_trg = torch.from_numpy(emb_trg[np.newaxis, :]).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            _, x_identic_psnt, _ = self.G(uttr_org, emb_org, emb_trg)\n",
    "        if len_pad == 0:\n",
    "            uttr_trg = x_identic_psnt[0, 0, :, :].cpu().numpy()\n",
    "        else:\n",
    "            uttr_trg = x_identic_psnt[0, 0, :-len_pad, :].cpu().numpy()\n",
    "            \n",
    "        return uttr_trg\n",
    "    \n",
    "    @staticmethod\n",
    "    def pad_seq(x, base=32):\n",
    "        len_out = int(base * ceil(float(x.shape[0])/base))\n",
    "        len_pad = len_out - x.shape[0]\n",
    "        assert len_pad >= 0\n",
    "        return np.pad(x, ((0,len_pad),(0,0)), 'constant'), len_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "enhanced-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocoder():\n",
    "    def __init__(self):\n",
    "        device = torch.device(\"cuda\")\n",
    "        model = build_model().to(device)\n",
    "        checkpoint = torch.load(\"checkpoint_step001000000_ema.pth\")\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, spec):\n",
    "        waveform = wavegen(self.model, spec)\n",
    "        return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dramatic-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "SE = SpeakerEmbedder()\n",
    "x_org = SpeakerEmbedder.melspec('/home/tony/D/corpus/data_aishell/wav/test/BAC009S0764W0491.wav')\n",
    "emb_org = SE('/home/tony/D/corpus/data_aishell/wav/test/BAC009S0764W0491.wav')\n",
    "emb_trg = SE(\"/home/tony/D/corpus/data_aishell/wav/test/BAC009S0764W0491.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "psychological-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP=SpeechConverter()\n",
    "x_trg = SP(x_org,emb_org,emb_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-gates",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 30629/103680 [04:34<11:00, 110.53it/s]"
     ]
    }
   ],
   "source": [
    "VD = Vocoder()\n",
    "wav = VD(x_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = BytesIO()\n",
    "librosa.output.write_wav(f, wav, sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=f.read(), rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='/home/tony/D/corpus/data_aishell/wav/test/BAC009S0764W0491.wav', rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename='/home/tony/D/corpus/data_aishell/wav/test/BAC009S0768W0185.wav', rate=16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
